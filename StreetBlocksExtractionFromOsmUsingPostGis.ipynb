{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> <font size=6> <b> Table of Contents </b> </font> </center> \n",
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The following cell is a Javascript section of code for building the Jupyter notebook's table of content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> <font size=5> <h1>Dependency</h1> </font> </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process depend from different software. Please instal them.\n",
    "- Please install [psycopg2](http://initd.org/psycopg/) which is used to interact between the Jupyter notebook and a PostgreSql database. On Linux, this command-line should works: `pip install psycopg2`\n",
    "- Please install [osm2pgsql](http://wiki.openstreetmap.org/wiki/Osm2pgsql#Installation) which is command-line based program used to import .osm file in a PostgreSql database. For Windows user, you could find the osm2pgsql executable. Go to [this website](https://ci.appveyor.com/project/openstreetmap/osm2pgsql/history) and find the latest 'artifact'. For Linux user, this command-line should works: `sudo apt-get install osm2pgsql`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> <font size=5> <h1>Define working environment</h1> </font> </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The following cells are used to: \n",
    "- Import needed libraries\n",
    "- Set the environment variables for Python, Anaconda, GRASS GIS and R statistical computing \n",
    "- Define the [\"GRASSDATA\" folder](https://grass.osgeo.org/grass73/manuals/helptext.html), the name of \"location\" and \"mapset\" where you will to work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "## Import libraries needed for setting parameters of operating system \n",
    "import os\n",
    "import sys\n",
    "\n",
    "## Import library for temporary files creation \n",
    "import tempfile \n",
    "\n",
    "## Import Numpy library\n",
    "import numpy as np\n",
    "\n",
    "## Import Psycopg2 library (interection with postgres database)\n",
    "import psycopg2 as pg\n",
    "\n",
    "## Import Pandas library (View and manipulaiton of tables)\n",
    "import pandas as pd\n",
    "\n",
    "## Import Subprocess + subprocess.call\n",
    "import subprocess\n",
    "from subprocess import call, Popen, PIPE, STDOUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Create dictionnary for user inputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Define a empty dictionnary for saving user inputs\n",
    "user={}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> <font size=5> <h3>Environment variables</h3> </font> </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Set 'Python' and 'GRASS GIS' environment variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Here, we set [the environment variables allowing to use of GRASS GIS](https://grass.osgeo.org/grass72/manuals/variables.html) inside this Jupyter notebook. Please change the directory path according to your own system configuration. Here after, possible paths are provided for different environment: \n",
    "- Windows7, using Anaconda2 and GRASS GIS 7.3svn standalone instal.\n",
    "- Linux Mint Serena (18.1) and GRASS GIS 7.3. Suggestions about environmental variables for Linux can be found here : [1](https://code.google.com/archive/p/postgis-grass-r-py/wikis/0003_01_PythonForGrassGis.wiki), [2](https://grasswiki.osgeo.org/wiki/Working_with_GRASS_without_starting_it_explicitly#Python:_GRASS_GIS_7_without_existing_location_using_metadata_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "### Define GRASS GIS environment variables for LINUX UBUNTU Mint 18.1 (Serena)\n",
    "# Check is environmental variables exists and create them (empty) if not exists.\n",
    "if not 'PYTHONPATH' in os.environ:\n",
    "    os.environ['PYTHONPATH']=''\n",
    "if not 'LD_LIBRARY_PATH' in os.environ:\n",
    "    os.environ['LD_LIBRARY_PATH']=''\n",
    "# Set environmental variables\n",
    "os.environ['GISBASE'] = '/usr/lib/grass73'\n",
    "os.environ['PATH'] += os.pathsep + os.path.join(os.environ['GISBASE'],'bin')\n",
    "os.environ['PATH'] += os.pathsep + os.path.join(os.environ['GISBASE'],'script')\n",
    "os.environ['PATH'] += os.pathsep + os.path.join(os.environ['GISBASE'],'lib')\n",
    "#os.environ['PATH'] += os.pathsep + os.path.join(os.environ['GISBASE'],'etc','python')\n",
    "os.environ['PYTHONPATH'] += os.pathsep + os.path.join(os.environ['GISBASE'],'etc','python')\n",
    "os.environ['PYTHONPATH'] += os.pathsep + os.path.join(os.environ['GISBASE'],'etc','python','grass')\n",
    "os.environ['PYTHONPATH'] += os.pathsep + os.path.join(os.environ['GISBASE'],'etc','python','grass','script')\n",
    "os.environ['PYTHONLIB'] = '/usr/lib/python2.7'\n",
    "os.environ['LD_LIBRARY_PATH'] += os.pathsep + os.path.join(os.environ['GISBASE'],'lib')\n",
    "os.environ['GIS_LOCK'] = '$$'\n",
    "os.environ['GISRC'] = os.path.join(os.environ['HOME'],'.grass7','rc')\n",
    "\n",
    "## Define GRASS-Python environment\n",
    "sys.path.append(os.path.join(os.environ['GISBASE'],'etc','python'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Set environment variables for Osm2psgsql**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Enter the path to the osm2pgsql folder\n",
    "user[\"osm2pgsqlfolder\"]=\"/usr/bin/osm2pgsql\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the path to the osm2pgsql default.style file\n",
    "user[\"stylefile\"]=\"/usr/share/osm2pgsql/default_OSMmetadata.style\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <font size=5> <h1>Define functions</h1> </font> </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section of the notebook is dedicated to defining functions which will then be called later in the script. If you want to create your own functions, define them here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for computing processing time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"print_processing_time\" is used to calculate and display the processing time for various stages of the processing chain. At the beginning of each major step, the current time is stored in a new variable, using [time.time() function](https://docs.python.org/2/library/time.html). At the end of the stage in question, the \"print_processing_time\" function is called and takes as argument the name of this new variable containing the recorded time at the beginning of the stage, and an output message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import library for managing time in python\n",
    "import time  \n",
    "\n",
    "## Function \"print_processing_time()\" compute processing time and printing it.\n",
    "# The argument \"begintime\" wait for a variable containing the begintime (result of time.time()) of the process for which to compute processing time.\n",
    "# The argument \"printmessage\" wait for a string format with information about the process. \n",
    "def print_processing_time(begintime, printmessage):    \n",
    "    endtime=time.time()           \n",
    "    processtime=endtime-begintime\n",
    "    remainingtime=processtime\n",
    "\n",
    "    days=int((remainingtime)/86400)\n",
    "    remainingtime-=(days*86400)\n",
    "    hours=int((remainingtime)/3600)\n",
    "    remainingtime-=(hours*3600)\n",
    "    minutes=int((remainingtime)/60)\n",
    "    remainingtime-=(minutes*60)\n",
    "    seconds=round((remainingtime)%60,1)\n",
    "\n",
    "    if processtime<60:\n",
    "        finalprintmessage=str(printmessage)+str(seconds)+\" seconds\"\n",
    "    elif processtime<3600:\n",
    "        finalprintmessage=str(printmessage)+str(minutes)+\" minutes and \"+str(seconds)+\" seconds\"\n",
    "    elif processtime<86400:\n",
    "        finalprintmessage=str(printmessage)+str(hours)+\" hours and \"+str(minutes)+\" minutes and \"+str(seconds)+\" seconds\"\n",
    "    elif processtime>=86400:\n",
    "        finalprintmessage=str(printmessage)+str(days)+\" days, \"+str(hours)+\" hours and \"+str(minutes)+\" minutes and \"+str(seconds)+\" seconds\"\n",
    "    \n",
    "    return finalprintmessage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Postgresql database vaccum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do a VACUUM on the current Postgresql database\n",
    "def vacuum(db):\n",
    "    old_isolation_level = db.isolation_level\n",
    "    db.set_isolation_level(0)\n",
    "    query = \"VACUUM\"\n",
    "    cur.execute(query)\n",
    "    db.set_isolation_level(old_isolation_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <font size=5> <h1>User inputs</h1> </font> </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here after:\n",
    "- Enter the name of the location projection information as an [EPSG code](http://spatialreference.org/ref/epsg/). \n",
    "- The environment variables of Postgresql will be defined. [More info here](https://www.postgresql.org/docs/9.3/static/libpq-envars.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Enter the EPSG code for this location \n",
    "user[\"locationepsg\"] = \"32630\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Enter postgresqgl host\n",
    "user[\"host\"] = \"localhost\"\n",
    "## Enter DB port\n",
    "user[\"port\"] = \"5432\"\n",
    "## Enter the postgresqgl username\n",
    "user[\"user\"] = \"tais\"\n",
    "## Enter postgresqgl Password\n",
    "user[\"password\"] = \"tais\"\n",
    "## Enter postgresqgl schema\n",
    "user[\"schema\"] = \"public\"\n",
    "## Enter the name of the new postgresqgl database\n",
    "user[\"dbname\"] = \"urbanblock_new\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set environmental variables for Postgresql\n",
    "os.environ['PGHOST'] = user[\"host\"]\n",
    "os.environ['PGPORT'] = user[\"port\"]\n",
    "os.environ['PGUSER'] = user[\"user\"]\n",
    "os.environ['PGPASSWORD'] = user[\"password\"]\n",
    "os.environ['PGDATABASE'] = user[\"dbname\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here after:\n",
    "- Enter the path to the folder where .osm file covering your area of interest will be downloaded. \n",
    "OSM data downloading is automated in this script. In case you would manage yourself the retrieving of OSM data, please read the [official wiki page](http://wiki.openstreetmap.org/wiki/Downloading_data) for that purpose. In tha case some parts of tis notebook should be adapted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Enter the path to the .osm file\n",
    "user[\"osmfolder\"]=\"/media/tais/data/MAUPP/Donnees_brutes/OSM/Ouagadougou\"\n",
    "## Enter the prefix you want to be used in the PostGIS DB\n",
    "user[\"prefixosm\"]=\"ouaga_osm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <font size=5> <h1>Import data in PostGIS databse</h1> </font>  </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Saving current time for processing time management\n",
    "begintime_blockextraction_full=time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create PostGis database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create database and extensions \"postgis\" and \"postgis_topology\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "\n",
    "# Connect to postgres database\n",
    "db=pg.connect(dbname='postgres', user=user[\"user\"], password=user[\"password\"], host=user[\"host\"])\n",
    "cur=db.cursor()\n",
    "# Allow to create a new database\n",
    "db.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "# Drop the database if it exists, and create a new one \n",
    "#cur.execute('DROP DATABASE IF EXISTS ' + user[\"dbname\"]) #Comment this to avoid deleting existing DB\n",
    "cur.execute('CREATE DATABASE ' + user[\"dbname\"])\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "# Close connection with database\n",
    "cur.close()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect to the new database\n",
    "db=pg.connect(dbname=user[\"dbname\"], user=user[\"user\"], password=user[\"password\"], host=user[\"host\"])\n",
    "cur=db.cursor()\n",
    "# Create the postgis extension\n",
    "cur.execute('CREATE EXTENSION IF NOT EXISTS postgis')\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "# Drop table if exists:\n",
    "cur.execute('CREATE EXTENSION IF NOT EXISTS postgis_topology')\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "# Make vaccum\n",
    "vacuum(db)\n",
    "# Close connection with database\n",
    "cur.close()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import additional vector layers (shapefile) in PostGis DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following part used the \"shp2pgsql\" program which should already be installed since postgis extension have been created in postgresql. See [this quick guide](http://www.bostongis.com/pgsql2shp_shp2pgsql_quickguide.bqg) for more information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 'Area of interest' or 'Morphological zones'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please notice that the attribute table of the shapefile to be imported need to have at least one column nammed \"type\" with integer values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Path to shapefile\n",
    "pathtofile1=\"/media/tais/data/MAUPP/WorldView3_Ouagadougou/Decoupage_Morpho/Shape_limites_zonesmorpho_Ouaga/Orthorectified/Refined_version/Zone_morpho_Ouaga_refined.shp\"\n",
    "## Enter postgresqgl table's name\n",
    "user[\"morphotable\"] = \"morpho_delineation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check if shapefile contain a column nammed 'type' which is integer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import geopandas as gpd\n",
    "import numpy\n",
    "\n",
    "df = gpd.read_file(pathtofile1) # Read the shapefile as a GeoDataframe \n",
    "list_columns=[str(a) for a in df.keys()] # Create a list with attribute table colum names\n",
    "if 'type' not in list_columns: # Check if column 'type' exists\n",
    "    sys.exit(\"There is columns nammed 'type' in the provided shapefile. Please fix it and try again\")\n",
    "if not isinstance(df['type'][0], numpy.int64): # Check if column 'type' in integer\n",
    "    sys.exit(\"The columns nammed 'type' is not declared as INTEGER. Please fix it and try again\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trick to be Popen like following was found [here](https://gis.stackexchange.com/a/58242/91497)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import shapefile in Postgresql using 'shp2pgsql' (command line passed via 'Popen')\n",
    "from subprocess import Popen, PIPE, STDOUT\n",
    "p1=Popen(['shp2pgsql','-s','%s:3857'%user[\"locationepsg\"],\n",
    "           '-d','-I',pathtofile1,user[\"schema\"]+\".\"+user[\"morphotable\"]],stdout=PIPE, stderr=PIPE)\n",
    "p2=Popen([\"psql\",\"-d\",user[\"dbname\"]], stdin=p1.stdout, stdout=PIPE, stderr=PIPE)    \n",
    "p1.stdout.close()\n",
    "stdout, stderr=p2.communicate()\n",
    "print(\"############ STANDART OUTPUT ############\"+\"\\n\\n\\n\"+stdout)\n",
    "if stderr:\n",
    "    print(\"############ STANDART ERROR ############\"+\"\\n\\n\\n\"+stderr)\n",
    "else:\n",
    "    print(\"############ NO ERROR TO PRINT ############\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**UPDATE last created PostGis table to ensure all geometries are valid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Connect to an existing database\n",
    "db=pg.connect(dbname=user[\"dbname\"], user=user[\"user\"], password=user[\"password\"], host=user[\"host\"])\n",
    "# Open a cursor to perform database operations\n",
    "cur=db.cursor()\n",
    "\n",
    "# Query\n",
    "query=\"UPDATE \"+user[\"schema\"]+\".\"+user[\"morphotable\"]+\" \\\n",
    "SET geom = ST_Multi(ST_CollectionExtract(ST_MakeValid(geom), 3)) \\\n",
    "WHERE ST_IsValid(geom) is not True\"\n",
    "# Execute the CREATE TABLE query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "   \n",
    "# Close cursor and communication with the database\n",
    "cur.close()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Area Of Interest of the city (AOI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Enter postgresqgl table's name\n",
    "user[\"AOI\"] = \"AOI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect to an existing database\n",
    "db=pg.connect(dbname=user[\"dbname\"], user=user[\"user\"], password=user[\"password\"], host=user[\"host\"])\n",
    "# Open a cursor to perform database operations\n",
    "cur=db.cursor()\n",
    "# Drop table if exists:\n",
    "cur.execute(\"DROP TABLE IF EXISTS \"+user[\"schema\"]+\".\"+user[\"AOI\"])\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "# Make vaccum\n",
    "vacuum(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Create a polygon with the AOI from the morphological zones\n",
    "# Subquery\n",
    "subquery1=\"SELECT ST_MakePolygon(ST_ExteriorRing(ST_Union(ST_MakeValid(geom)))) AS the_geom \\\n",
    "FROM \"+user[\"schema\"]+\".\"+user[\"morphotable\"]\n",
    "# Query\n",
    "query=\"CREATE TABLE \"+user[\"schema\"]+\".\"+user[\"AOI\"]+\" AS (\"\n",
    "query+=subquery1+\")\"\n",
    "# Execute the CREATE TABLE query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "\n",
    "# Create spatial index on the geometry column:\n",
    "cur.execute(\"CREATE INDEX \"+user[\"AOI\"]+\"_gix\"+\" ON \"+user[\"schema\"]+\".\"+user[\"AOI\"]+\" USING GIST (the_geom)\")\n",
    "# Make the changes to the database persistent\n",
    "db.commit() \n",
    "\n",
    "# Close cursor and communication with the database\n",
    "cur.close()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Query to find the number of row in the sample table\n",
    "# Connect to an existing database\n",
    "db=pg.connect(dbname=user[\"dbname\"], user=user[\"user\"], password=user[\"password\"], host=user[\"host\"])\n",
    "# Query to find the number of row in the  table\n",
    "query=\"SELECT count(*) as nbr FROM \"+user[\"schema\"]+\".\"+user[\"AOI\"] \n",
    "# Execute query through panda\n",
    "df=pd.read_sql(query, db)\n",
    "# Save the number of items a variable\n",
    "nbr_blocks=list(df['nbr'])[0]\n",
    "# Print\n",
    "print \"Number of items : \"+str(nbr_blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiles covering the extent of the AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Enter postgresqgl table's name\n",
    "user[\"tile\"] = \"tile\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect to an existing database\n",
    "db=pg.connect(dbname=user[\"dbname\"], user=user[\"user\"], password=user[\"password\"], host=user[\"host\"])\n",
    "# Open a cursor to perform database operations\n",
    "cur=db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop table if exists:\n",
    "cur.execute(\"DROP TABLE IF EXISTS \"+user[\"schema\"]+\".\"+user[\"tile\"])\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "# Make vaccum\n",
    "vacuum(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Save the previous subquery1 results in a new table\n",
    "# Connect to an existing database\n",
    "db=pg.connect(dbname=user[\"dbname\"], user=user[\"user\"], password=user[\"password\"], host=user[\"host\"])\n",
    "# Open a cursor to perform database operations\n",
    "cur=db.cursor()\n",
    "\n",
    "subquery1=\"WITH \\\n",
    "first_BBox AS(\\\n",
    "SELECT ST_Segmentize(ST_Envelope(the_geom),(ST_Perimeter(the_geom)/(4*2))) as the_geom \\\n",
    "FROM public.aoi),\\\n",
    " \\\n",
    "first_subdivide AS(\\\n",
    "SELECT ST_Subdivide(the_geom,8) AS the_geom \\\n",
    "FROM first_BBox),\\\n",
    " \\\n",
    "second_BBox AS(\\\n",
    "SELECT ST_Segmentize(ST_Envelope(the_geom),(ST_Perimeter(the_geom)/(4*2))) as the_geom \\\n",
    "FROM first_subdivide)\\\n",
    " \\\n",
    "SELECT ST_Subdivide(the_geom,8) AS the_geom \\\n",
    "FROM second_BBox\"\n",
    "\n",
    "# Query\n",
    "query=\"CREATE TABLE \"+user[\"schema\"]+\".\"+user[\"tile\"]+\" AS (\"\n",
    "query+=subquery1+\")\"\n",
    "\n",
    "# Execute the CREATE TABLE query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "# Close cursor and communication with the database\n",
    "cur.close()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a 'gid' SERIAL primary key and create a spatial index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect to an existing database\n",
    "db=pg.connect(dbname=user[\"dbname\"], user=user[\"user\"], password=user[\"password\"], host=user[\"host\"])\n",
    "# Open a cursor to perform database operations\n",
    "cur=db.cursor()\n",
    "# Query\n",
    "query=\"ALTER TABLE \"+user[\"schema\"]+\".\"+user[\"tile\"]+\" ADD COLUMN gid SERIAL PRIMARY KEY\"\n",
    "# Execute the CREATE TABLE query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "\n",
    "# Create spatial index:\n",
    "cur.execute(\"CREATE INDEX \"+user[\"tile\"]+\"_gix\"+\" ON \"+user[\"schema\"]+\".\"+user[\"tile\"]+\" USING GIST (the_geom)\")\n",
    "# Make the changes to the database persistent\n",
    "db.commit() \n",
    "\n",
    "# Close cursor and communication with the database\n",
    "cur.close()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Query to find the number of row in the sample table\n",
    "# Connect to an existing database\n",
    "db=pg.connect(dbname=user[\"dbname\"], user=user[\"user\"], password=user[\"password\"], host=user[\"host\"])\n",
    "# Query to find the number of row in the  table\n",
    "query=\"SELECT count(*) as nbr FROM \"+user[\"schema\"]+\".\"+user[\"tile\"] \n",
    "# Execute query through panda\n",
    "df=pd.read_sql(query, db)\n",
    "# Save the number of items a variable\n",
    "nbr_tiles=list(df['nbr'])[0]\n",
    "# Print\n",
    "print \"Number of items : \"+str(nbr_tiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get upper, lower, right and left coordinates of each tile (in WGS84)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: the following query works for North hemisphere, west longitudes. Adapt ST_Ymin,ST_Ymax,ST_Xmin,ST_Xmax according to your geographical region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Enter postgresqgl table's mane\n",
    "user[\"tile_coord\"] = \"tile_coord\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Save the previous subquery1 results in a new table\n",
    "# Connect to an existing database\n",
    "db=pg.connect(dbname=user[\"dbname\"], user=user[\"user\"], password=user[\"password\"], host=user[\"host\"])\n",
    "# Open a cursor to perform database operations\n",
    "cur=db.cursor()\n",
    "\n",
    "# Query\n",
    "query=\"WITH \\\n",
    "wgs84geom AS(\\\n",
    "SELECT  gid, ST_Transform(the_geom, 4326) AS the_geom \\\n",
    "FROM \"+user[\"schema\"]+\".\"+user[\"tile\"]+\") \\\n",
    "\\\n",
    "SELECT gid, ST_Xmin(the_geom) AS west, ST_Xmax(the_geom) AS east, \\\n",
    "ST_Ymin(the_geom) AS south, ST_Ymax(the_geom) AS north \\\n",
    "FROM wgs84geom\"\n",
    "\n",
    "# Execute query through panda\n",
    "df_tiles_coord=pd.read_sql(query, db)\n",
    "# Close cursor and communication with the database\n",
    "cur.close()\n",
    "db.close()\n",
    "# Show dataframe\n",
    "df_tiles_coord.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajust the tiles to the AOI (ST_Intersection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Enter postgresqgl table's name\n",
    "user[\"aoi_tile\"] = \"AOI_tile\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect to an existing database\n",
    "db=pg.connect(dbname=user[\"dbname\"], user=user[\"user\"], password=user[\"password\"], host=user[\"host\"])\n",
    "# Open a cursor to perform database operations\n",
    "cur=db.cursor()\n",
    "\n",
    "# Drop table if exists:\n",
    "cur.execute(\"DROP TABLE IF EXISTS \"+user[\"schema\"]+\".\"+user[\"aoi_tile\"])\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "# Make vaccum\n",
    "vacuum(db)\n",
    "\n",
    "# Subquery with the new 'the_geom' column resulting from ST_Interection\n",
    "subquery=\"WITH aoi_buffered AS (\\\n",
    "SELECT ST_Buffer(the_geom,0.01) AS the_geom \\\n",
    "FROM \"+user[\"schema\"]+\".\"+user[\"AOI\"]+\") \\\n",
    "\\\n",
    "SELECT \\\n",
    "tile.gid AS gid, \\\n",
    "ST_Intersection(aoi.the_geom, tile.the_geom) as the_geom \\\n",
    "FROM aoi_buffered AS aoi,\"+user[\"schema\"]+\".\"+user[\"tile\"]+\" AS tile \\\n",
    "WHERE ST_Intersects(aoi.the_geom, tile.the_geom)\"\n",
    "\n",
    "# Query\n",
    "query=\"CREATE TABLE \"+user[\"schema\"]+\".\"+user[\"aoi_tile\"]+\" AS (\"\n",
    "query+=subquery+\")\"\n",
    "\n",
    "# Execute the CREATE TABLE query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "# Close cursor and communication with the database\n",
    "cur.close()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenStreetMap data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trick to extract polygons from lines was found [here](http://gis.stackexchange.com/questions/83/separate-polygons-based-on-intersection-using-postgis)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download OpenStreetMap data using Xapi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More information about Xapi can be found [here](http://wiki.openstreetmap.org/wiki/Xapi)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import urllib\n",
    "\n",
    "## Saving current time for processing time management\n",
    "begintime_download=time.time()\n",
    "  \n",
    "## Save the suffix corresponding to the date of today\n",
    "now=datetime.datetime.now()\n",
    "date_suffix=str(now.year)+str(now.month)+str(now.day)\n",
    "\n",
    "for tilenum in range(1,nbr_tiles+1):\n",
    "    loopstarttime=time.time()\n",
    "    north_coord=round(list(df_tiles_coord.loc[tilenum-1,['north']])[0],6)\n",
    "    south_coord=round(list(df_tiles_coord.loc[tilenum-1,['south']])[0],6)\n",
    "    west_coord=round(list(df_tiles_coord.loc[tilenum-1,['west']])[0],6)\n",
    "    east_coord=round(list(df_tiles_coord.loc[tilenum-1,['east']])[0],6)\n",
    "    print \"OSM data will be downloaded for tile n°\"+str(tilenum)+\" (W:\"+str(west_coord)+\" S:\"+str(south_coord)+\" E:\"+str(east_coord)+\" N:\"+str(north_coord)+\")\"\n",
    "    \n",
    "    osm_api_base_url=\"http://www.overpass-api.de/api/xapi?*\"\n",
    "    osm_api_query_url=osm_api_base_url+\"[bbox=\"+str(west_coord)+\",\"+str(south_coord)+\",\"+str(east_coord)+\",\"+str(north_coord)+\"][@meta]\"\n",
    "    \n",
    "    #osm_file=user[\"osmfolder\"]+\"/\"+user[\"prefixosm\"]+\"_\"+str(now.year)+str(now.month)+str(now.day)+\"_\"+str(tilenum)+\".osm\"\n",
    "    osm_file=os.path.join(user[\"osmfolder\"],user[\"prefixosm\"]+\"_\"+date_suffix+\"_\"+str(tilenum)+\".osm\")\n",
    "\n",
    "    success=False\n",
    "    while success==False and (time.time()-loopstarttime)<1800:  # Will stop looping is running for more than 30 minutes\n",
    "        try:\n",
    "            urllib.urlretrieve(osm_api_query_url, osm_file)\n",
    "        except:\n",
    "            print \"An error occured for tile n°%s. Please check and retry.\"%tilenum\n",
    "        if os.stat(osm_file).st_size>280: # If the .osm file do not contain any geometry (size should be less than 275 bytes)\n",
    "            success=True\n",
    "            \n",
    "    print osm_api_query_url\n",
    "    \n",
    "## Print\n",
    "print print_processing_time(begintime_download, \"OSM Data downloaded in \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import OpenStreetMap layers in PostGis DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here after, the OpenStreetMap data will be imported in the Postgresql Database. [Osm2pgsql](http://wiki.openstreetmap.org/wiki/Osm2pgsql) is used for this purpose. Informations can be found in [this github repository](https://github.com/openstreetmap/osm2pgsql). If you are working on Windows, this tool cand be found on [this website](https://ci.appveyor.com/project/openstreetmap/osm2pgsql/history) (please look for the latest 'artifact').\n",
    "\n",
    "The parameter to be used are explained [here](http://www.volkerschatz.com/net/osm/osm2pgsql-usage.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Please choose the version of .osm dataset to be used. \n",
    "# If you want to use the dataset which has just been downloaded (previous step), please use 'yes' value for \n",
    "# the \"use_today_dataset\" variable. If not, please use 'no' and update the \"date_suffix\" variable according\n",
    "# to the version of the dataset you want to be used (avoid zero, e.g. 201756 for the 6 of May 2017)\n",
    "use_today_dataset='no'\n",
    "if use_today_dataset=='no':\n",
    "    date_suffix='2017816'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loop through the stack of tiles\n",
    "for tilenum in range(1,nbr_tiles+1):\n",
    "    ## Call osm2pgsql as a subprocess\n",
    "    p=Popen(['osm2pgsql','-c','-d',user[\"dbname\"],'-U',user[\"user\"],'-H',user[\"host\"],\n",
    "              '--extra-attributes','-E','3857',\n",
    "              '-p',user[\"prefixosm\"]+\"_\"+date_suffix+\"_\"+str(tilenum),\n",
    "              '-S',user[\"stylefile\"],\n",
    "              os.path.join(user[\"osmfolder\"],user[\"prefixosm\"]+\"_\"+date_suffix+\"_\"+str(tilenum)+\".osm\")],\n",
    "            env={'PGPASS': user[\"password\"]},\n",
    "            stdin=PIPE,stdout=PIPE,stderr=STDOUT)\n",
    "    stdout,stderr=p.communicate()\n",
    "    print(\"############ STANDART OUTPUT ############\"+\"\\n\\n\\n\"+stdout)\n",
    "    if stderr:\n",
    "        print(\"############ STANDART ERROR ############\"+\"\\n\\n\\n\"+stderr)\n",
    "    else:\n",
    "        print(\"############ NO ERROR TO PRINT ############\"+\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here after, the osm table \"poin\" and \"roads\" will be droped as they will not be used in our processings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Drop tables \"point\" and \"roads\" which will not be used in this script\n",
    "\n",
    "# Connect to an existing database\n",
    "db=pg.connect(dbname=user[\"dbname\"], user=user[\"user\"], password=user[\"password\"], host=user[\"host\"])\n",
    "# Open a cursor to perform database operations\n",
    "cur=db.cursor()\n",
    "\n",
    "for tilenum in range(1,nbr_tiles+1):\n",
    "    # Drop table if exists:\n",
    "    cur.execute(\"DROP TABLE IF EXISTS \"+user[\"schema\"]+\".\"+\"\\\n",
    "    \"+user[\"prefixosm\"]+\"_\"+date_suffix+\"_\"+str(tilenum)+\"_\"+\"point\")\n",
    "\n",
    "    # Drop table if exists:\n",
    "    cur.execute(\"DROP TABLE IF EXISTS \"+user[\"schema\"]+\".\"+\"\\\n",
    "    \"+user[\"prefixosm\"]+\"_\"+date_suffix+\"_\"+str(tilenum)+\"_\"+\"roads\")\n",
    "    \n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "# Make vaccum\n",
    "vacuum(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here after, the name of the osm table will be saved in dictionnaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Define a empty dictionnary for saving osm line and polygon table names\n",
    "osm_line={}\n",
    "osm_polygon={}\n",
    "\n",
    "## Loop through the stack of tiles\n",
    "for tilenum in range(1,nbr_tiles+1):\n",
    "    # Save the table postgis table name in the dictionnary\n",
    "    osm_line[\"tile_\"+str(tilenum)]=user[\"prefixosm\"]+\"_\"+date_suffix+\"_\"+str(tilenum)+\"_line\"\n",
    "    osm_polygon[\"tile_\"+str(tilenum)]=user[\"prefixosm\"]+\"_\"+date_suffix+\"_\"+str(tilenum)+\"_polygon\"\n",
    "    \n",
    "#### Display name of osm tables\n",
    "for tile in osm_line.keys():\n",
    "    print osm_line[tile]+\"    \"+osm_polygon[tile]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> *-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*- </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract urban blocks for each tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Save names of linestrings and blocks for each tile\n",
    "linestrings={}\n",
    "for tile in osm_line.keys()[:]:\n",
    "    linestrings[tile] = \"linestrings\"+\"_\"+str(tile)\n",
    "    print linestrings[tile]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract linestrings from different sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When unioning all the linestring together, an \"TopologyException\" could appear. To avoid it, the [\"ST_SnapToGrid\"](https://postgis.net/docs/ST_SnapToGrid.html) function is used. The latter required a parameter defining the resolution of the grid on which to perform the snap operation. This parameter is nammed here 'snaptogrid_param'. Sometime, a specific value of this parameter will return an error similar to the following: \"GEOSUnaryUnion: TopologyException: found non-noded intersection between\". To avoid it, the procedure will automatically inscrease the 'snaptogrid_param' is an error occured. The trick to solve this issue was found [here](https://gis.stackexchange.com/a/90271/91497)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_snapped_unioned_linestrings(db_connexion,db_schema,newtable_name,aoi,aoi_tile,\n",
    "                                        osm_lines,osm_polygons,morphologiczones,epsg,\n",
    "                                        snaptogrid_param,tile_gid):\n",
    "    # Open a cursor to perform database operations\n",
    "    cur=db_connexion.cursor()\n",
    "    # Drop table if exists:\n",
    "    cur.execute(\"DROP TABLE IF EXISTS %s.%s\"%(db_schema,newtable_name))\n",
    "    # Make the changes to the database persistent\n",
    "    db_connexion.commit()\n",
    "\n",
    "    # Subquery for extraction of linestrings from different sources\n",
    "    subquery1=\"WITH \\\n",
    "    current_tile AS (\\\n",
    "    SELECT the_geom FROM \"+db_schema+\".\"+aoi_tile+\" AS tile \\\n",
    "    WHERE gid=\"+tile_gid+\"), \\\n",
    "    \\\n",
    "    linestrings AS (\\\n",
    "    SELECT  ST_ExteriorRing(aoi.the_geom) AS the_geom \\\n",
    "    FROM \"+db_schema+\".\"+aoi+\" AS aoi \\\n",
    "    \\\n",
    "    UNION ALL \\\n",
    "    \\\n",
    "    SELECT ST_SnapToGrid(l.way,\"+str(snaptogrid_param)+\") AS the_geom \\\n",
    "    FROM \"+db_schema+\".\"+osm_lines+\" AS l, current_tile \\\n",
    "    WHERE (l.highway is not null OR l.waterway is not null OR l.railway is not null) \\\n",
    "    AND ST_Intersects(l.way, current_tile.the_geom) \\\n",
    "    \\\n",
    "    UNION ALL \\\n",
    "    \\\n",
    "    SELECT ST_SnapToGrid(ST_ExteriorRing((ST_DumpRings(morpho.geom)).geom),\"+str(snaptogrid_param)+\") AS the_geom \\\n",
    "    FROM (SELECT (ST_Dump(zm.geom)).* FROM \"+db_schema+\".\"+morphologiczones+\" AS zm) AS morpho, current_tile \\\n",
    "    WHERE ST_Intersects(morpho.geom, current_tile.the_geom) \\\n",
    "    \\\n",
    "    UNION ALL \\\n",
    "    \\\n",
    "    SELECT ST_SnapToGrid(ST_ExteriorRing((ST_DumpRings(naturpoly.geom)).geom),\"+str(snaptogrid_param)+\") AS the_geom \\\n",
    "    FROM (SELECT (ST_Dump(p.way)).* FROM \"+db_schema+\".\"+osm_polygons+\" AS p, current_tile  \\\n",
    "    WHERE p.natural is not null AND ST_Area(ST_Transform(p.way, \"+epsg+\"))>2500 \\\n",
    "    AND ST_Intersects(p.way, current_tile.the_geom)) AS naturpoly \\\n",
    "    \\\n",
    "    UNION ALL \\\n",
    "    \\\n",
    "    SELECT ST_SnapToGrid(ST_ExteriorRing((ST_DumpRings(amenities.geom)).geom),\"+str(snaptogrid_param)+\") AS the_geom \\\n",
    "    FROM (SELECT (ST_Dump(p.way)).* FROM \"+db_schema+\".\"+osm_polygons+\" AS p, current_tile  \\\n",
    "    WHERE p.amenity IN ('college','school','university','clinic','hospital') \\\n",
    "    AND ST_Area(ST_Transform(p.way, \"+epsg+\"))>1000 \\\n",
    "    AND ST_Intersects(p.way, current_tile.the_geom)) AS amenities \\\n",
    "    \\\n",
    "    UNION ALL\\\n",
    "    \\\n",
    "    SELECT ST_SnapToGrid(ST_ExteriorRing((ST_DumpRings(landusepoly.geom)).geom),\"+str(snaptogrid_param)+\") AS the_geom \\\n",
    "    FROM (SELECT (ST_Dump(p.way)).* FROM \"+db_schema+\".\"+osm_polygons+\" AS p, current_tile \\\n",
    "    WHERE (p.landuse is not null OR p.barrier is not null) \\\n",
    "    AND ST_Area(ST_Transform(p.way, \"+epsg+\"))>2500 \\\n",
    "    AND ST_Intersects(p.way, current_tile.the_geom)) AS landusepoly), \\\n",
    "    \\\n",
    "    tiled_linestrings AS (\\\n",
    "    SELECT CASE \\\n",
    "    WHEN ST_CoveredBy(ls.the_geom,tile.the_geom) \\\n",
    "    THEN ls.the_geom \\\n",
    "    ELSE ST_Intersection(ls.the_geom,tile.the_geom) \\\n",
    "    END As the_geom \\\n",
    "    FROM linestrings AS ls \\\n",
    "    INNER JOIN current_tile As tile \\\n",
    "    ON ST_Intersects(ls.the_geom,tile.the_geom)) \\\n",
    "    \\\n",
    "    SELECT (ST_Dump(the_geom)).geom AS the_geom \\\n",
    "    FROM (SELECT ST_Union(ST_MakeValid(the_geom)) AS the_geom FROM tiled_linestrings) AS noded_line\"\n",
    "\n",
    "    # Query\n",
    "    query=\"CREATE TABLE \"+db_schema+\".\"+newtable_name+\" AS (\"\n",
    "    query+=subquery1+\")\"\n",
    "    # Execute the CREATE TABLE query \n",
    "    cur.execute(query)\n",
    "    # Make the changes to the database persistent\n",
    "    db_connexion.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Saving current time for processing time management\n",
    "begintime_linestrings_total=time.time()\n",
    "\n",
    "# Define starting 'snaptogrid' parameter\n",
    "snaptogrid_param=0.04\n",
    "\n",
    "# Loop on each tile\n",
    "for tile in osm_line.keys()[:]:\n",
    "    begintime_linestrings_loop=time.time()\n",
    "    success=False\n",
    "    snap_param=float(snaptogrid_param)\n",
    "    while success==False and snap_param<0.5:\n",
    "        # Connect to an existing database\n",
    "        db=pg.connect(dbname=user[\"dbname\"], user=user[\"user\"], password=user[\"password\"], host=user[\"host\"])\n",
    "        print \"Processing tile n°%s with 'snaptogrid_param' equal to %s.\"%(tile.split(\"_\")[-1],snap_param)\n",
    "        try:\n",
    "            extract_snapped_unioned_linestrings(db,user[\"schema\"],linestrings[tile],\n",
    "                                                user[\"AOI\"],user[\"aoi_tile\"],osm_line[tile],osm_polygon[tile],\n",
    "                                                user[\"morphotable\"],user[\"locationepsg\"],\n",
    "                                                snap_param,tile[tile.index(\"_\")+1:])\n",
    "            print print_processing_time(begintime_linestrings_loop, \"Linestrings of '\"+str(tile)+\"' extracted in \")\n",
    "            print \"\\n\"\n",
    "            success=True\n",
    "        except Exception, e:\n",
    "            print e.pgerror\n",
    "            snap_param=round(snap_param+0.01,3)\n",
    "        # Close cursor and communication with the database\n",
    "        db.close()\n",
    "\n",
    "## Print\n",
    "print print_processing_time(begintime_linestrings_total, \"Process achieved in \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge all tiles together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Enter postgresqgl table's name\n",
    "user[\"linestrings_all\"] = \"linestrings_all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect to an existing database\n",
    "db=pg.connect(dbname=user[\"dbname\"], user=user[\"user\"], password=user[\"password\"], host=user[\"host\"])\n",
    "# Open a cursor to perform database operations\n",
    "cur=db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Saving current time for processing time management\n",
    "begintime_tilemerging=time.time()\n",
    "print \"Going to merge all tiles together\"\n",
    "\n",
    "# Drop table if exists:\n",
    "cur.execute(\"DROP TABLE IF EXISTS \"+user[\"schema\"]+\".\"+user[\"linestrings_all\"])\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "# Make vaccum\n",
    "vacuum(db)\n",
    "\n",
    "# Subquery\n",
    "subquery=\"WITH \\\n",
    "merged_tiles AS(\\\n",
    "SELECT all_tiles.the_geom AS the_geom \\\n",
    "FROM (\"\n",
    "for tile in linestrings.keys():\n",
    "    if tile not in linestrings.keys()[-1:]:\n",
    "        subquery+=\"SELECT * FROM \"+user[\"schema\"]+\".\"+linestrings[tile]+\" \\\n",
    "                    UNION ALL \\\n",
    "                    \"\n",
    "    else :\n",
    "        subquery+=\"SELECT * FROM \"+user[\"schema\"]+\".\"+linestrings[tile]+\") AS all_tiles) \"\n",
    "        \n",
    "subquery+=\"\\\n",
    "SELECT the_geom FROM merged_tiles\"\n",
    "\n",
    "# Query\n",
    "query=\"CREATE TABLE \"+user[\"schema\"]+\".\"+user[\"linestrings_all\"]+\" AS (\"\n",
    "query+=subquery+\")\"\n",
    "\n",
    "#print query \n",
    "# Execute the CREATE TABLE query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "\n",
    "# Add a SERIAL PRIMARY KEY on the table \n",
    "cur.execute(\"ALTER TABLE \"+user[\"schema\"]+\".\"+user[\"linestrings_all\"]+\" ADD COLUMN gid SERIAL PRIMARY KEY\")\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "\n",
    "## Print\n",
    "print print_processing_time(begintime_tilemerging, \"Linestrings from all tiles merged in \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Close cursor and communication with the database\n",
    "cur.close()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use PostGis topology to clean the linestrings network (snapping-like)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next section of this notebook is dedicated to snapping of near nodes. Because of the use of multiple different sources, it could result in a high number of duplicated linear items whith a slight displacement between them. As a preliminary step before construction of the street blocks, the [topology function of PosgtGis](http://postgis.net/docs/Topology.html) will be used as it allow to snap nodes according to a user-defined distance threshold. The trick implemented here was found on [Mathieu Leplatre's blog](http://blog.mathieu-leplatre.info/use-postgis-topologies-to-clean-up-road-networks.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the tolerance for snapping (in meters)\n",
    "tolerance=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "user[\"linestrings_all_snaped\"]=\"linestrings_all_snaped\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving current time for processing time management\n",
    "begintime_linestrings=time.time()\n",
    "\n",
    "# Connect to an existing database\n",
    "db=pg.connect(dbname=user[\"dbname\"], user=user[\"user\"], password=user[\"password\"], host=user[\"host\"])\n",
    "# Open a cursor to perform database operations\n",
    "cur=db.cursor()\n",
    "\n",
    "########## Clean the linestrings network using PostGis topology fonctions ##########\n",
    "topo_layer=\"linestring_topology\"\n",
    "\n",
    "# Query\n",
    "query=\"SELECT topology.DropTopology('\"+topo_layer+\"') \\\n",
    "WHERE EXISTS (SELECT * FROM topology.topology WHERE name='\"+topo_layer+\"')\"\n",
    "# Drop table if exists:\n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "\n",
    "# Query\n",
    "query=\"SELECT topology.CreateTopology('\"+topo_layer+\"', 3857, \"+str(tolerance)+\") \\\n",
    "WHERE NOT EXISTS (SELECT * FROM topology.topology WHERE name='\"+topo_layer+\"')\"\n",
    "# Drop table if exists:\n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "\n",
    "# Query\n",
    "query=\"SELECT topology.AddTopoGeometryColumn(\\\n",
    "'\"+topo_layer+\"','\"+user[\"schema\"]+\"','\"+user[\"linestrings_all\"]+\"','topo_geom','LINESTRING')\"\n",
    "# Drop table if exists:\n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "\n",
    "# Query\n",
    "query=\"\\\n",
    "DO $$DECLARE r record;\\\n",
    "BEGIN \\\n",
    "  FOR r IN SELECT * FROM \"+user[\"schema\"]+\".\"+user[\"linestrings_all\"]+\" LOOP \\\n",
    "    BEGIN \\\n",
    "      UPDATE \"+user[\"schema\"]+\".\"+user[\"linestrings_all\"]+\" \\\n",
    "        SET topo_geom = topology.toTopoGeom(the_geom, '\"+topo_layer+\"', 1, \"+str(tolerance)+\") \\\n",
    "      WHERE the_geom = r.the_geom; \\\n",
    "    EXCEPTION \\\n",
    "      WHEN OTHERS THEN \\\n",
    "        RAISE WARNING 'Loading of record % failed: %', r.the_geom, SQLERRM; \\\n",
    "    END; \\\n",
    "  END LOOP; \\\n",
    "END$$;\"\n",
    "# Drop table if exists:\n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "# Make vaccum\n",
    "vacuum(db)\n",
    "\n",
    "# Drop table if exists:\n",
    "cur.execute(\"DROP TABLE IF EXISTS \"+user[\"schema\"]+\".\"+user[\"linestrings_all_snaped\"])\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "# Make vaccum\n",
    "vacuum(db)\n",
    "\n",
    "# Subquery\n",
    "subquery=\"WITH \\\n",
    "valid_linestring AS(\\\n",
    "SELECT ST_MakeValid((ST_Dump(topo_geom::geometry)).geom) AS the_geom \\\n",
    "FROM \"+user[\"schema\"]+\".\"+user[\"linestrings_all\"]+\"), \\\n",
    "\\\n",
    "noded_linestring AS(\\\n",
    "SELECT (ST_Dump(ST_Union(the_geom))).geom AS the_geom FROM valid_linestring) \\\n",
    "\\\n",
    "SELECT * FROM noded_linestring\"\n",
    "# Query\n",
    "query=\"CREATE TABLE \"+user[\"schema\"]+\".\"+user[\"linestrings_all_snaped\"]+\" AS (\"\n",
    "query+=subquery+\")\"\n",
    "\n",
    "# Execute the query\n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit() \n",
    "    \n",
    "## Print\n",
    "print print_processing_time(begintime_linestrings, \"Process achieved in \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polygonize linestrings network to create urban blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Enter postgresqgl table's name\n",
    "user[\"street_blocks_with_artifacts\"] = \"street_blocks_with_artifacts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect to an existing database\n",
    "db=pg.connect(dbname=user[\"dbname\"], user=user[\"user\"], password=user[\"password\"], host=user[\"host\"])\n",
    "# Open a cursor to perform database operations\n",
    "cur=db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving current time for processing time management\n",
    "begintime_polygonize=time.time()\n",
    "\n",
    "# Drop table if exists:\n",
    "cur.execute(\"DROP TABLE IF EXISTS \"+user[\"schema\"]+\".\"+user[\"street_blocks_with_artifacts\"])\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "# Make vaccum\n",
    "vacuum(db)\n",
    "\n",
    "# Subquery for polygonization of mutlilinestrings\n",
    "subquery1=\"WITH \\\n",
    "multilinestring AS (\\\n",
    "SELECT ST_Multi(the_geom) AS the_geom \\\n",
    "FROM (SELECT ST_Collect(the_geom) AS the_geom \\\n",
    "      FROM \"+user[\"schema\"]+\".\"+user[\"linestrings_all_snaped\"]+\") As GeomCollection), \\\n",
    "\\\n",
    "valid_polygons AS (\\\n",
    "SELECT ST_CollectionExtract((ST_Dump(ST_MakeValid(the_geom))).geom,3) AS the_geom \\\n",
    "FROM (SELECT DISTINCT ST_CollectionExtract(((ST_Dump(ST_Polygonize(the_geom))).geom),3) AS the_geom \\\n",
    "FROM multilinestring) AS extracted_polygons) \\\n",
    "\\\n",
    "SELECT the_geom FROM valid_polygons\"\n",
    "\n",
    "# Query\n",
    "query=\"CREATE TABLE \"+user[\"schema\"]+\".\"+user[\"street_blocks_with_artifacts\"]+\" AS (\"\n",
    "query+=subquery1+\")\"\n",
    "# Execute the CREATE TABLE query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "# Add a SERIAL PRIMARY KEY on the table \n",
    "cur.execute(\"ALTER TABLE \"+user[\"schema\"]+\".\"+user[\"street_blocks_with_artifacts\"]+\" \\\n",
    "ADD COLUMN gid SERIAL PRIMARY KEY\")\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "    \n",
    "## Print\n",
    "print print_processing_time(begintime_polygonize, \"Process achieved in \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Query to find the number of row in the  table\n",
    "query=\"SELECT count(*) as nbr FROM \"+user[\"schema\"]+\".\"+user[\"street_blocks_with_artifacts\"]\n",
    "# Execute query through panda\n",
    "df=pd.read_sql(query, db)\n",
    "# Save the number of items a variable\n",
    "nbr_tiles=list(df['nbr'])[0]\n",
    "# Print\n",
    "print \"Number of blocks extracted : \"+str(nbr_tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Close cursor and communication with the database\n",
    "cur.close()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> *-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*- </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Remove artifact polygons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_nbrrowm(db, schema, table):\n",
    "    # Query to find the number of row in the  table\n",
    "    query=\"SELECT count(*) as nbr FROM \"+schema+\".\"+table\n",
    "    # Execute query through panda\n",
    "    df=pd.read_sql(query, db)\n",
    "    # Save the number of items a variable\n",
    "    nbr_row=list(df['nbr'])[0]\n",
    "    # Return\n",
    "    return nbr_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_area_perimeter_compactness(db, schema, table):\n",
    "    # Open a cursor to perform database operations\n",
    "    cur=db.cursor()\n",
    "    # Add columns if not exist\n",
    "    cur.execute(\"ALTER TABLE \"+schema+\".\"+table+\" \\\n",
    "    ADD COLUMN IF NOT EXISTS area double precision, \\\n",
    "    ADD COLUMN IF NOT EXISTS perimeter double precision, \\\n",
    "    ADD COLUMN IF NOT EXISTS compactness double precision\")\n",
    "    # Make the changes to the database persistent\n",
    "    db.commit()\n",
    "    # Update columns with values\n",
    "    cur.execute(\"UPDATE \"+schema+\".\"+table+\" \\\n",
    "    SET area=ST_Area(ST_Transform(the_geom,\"+user[\"locationepsg\"]+\")), \\\n",
    "    perimeter=ST_Perimeter(ST_Transform(the_geom,\"+user[\"locationepsg\"]+\")),\\\n",
    "    compactness=(ST_Perimeter(ST_Transform(the_geom,\"+user[\"locationepsg\"]+\"))/sqrt(\\\n",
    "    ST_Area(ST_Transform(the_geom,\"+user[\"locationepsg\"]+\"))))\")\n",
    "    # Make the changes to the database persistent\n",
    "    db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_morphoid_morphotype(db, schema, streetblocktable, morphotable):\n",
    "    # Open a cursor to perform database operations\n",
    "    cur=db.cursor()\n",
    "    # Add columns if not exist\n",
    "    cur.execute(\"ALTER TABLE \"+schema+\".\"+streetblocktable+\" \\\n",
    "    ADD COLUMN IF NOT EXISTS morpho_id integer, \\\n",
    "    ADD COLUMN IF NOT EXISTS morpho_type varchar(10) \")\n",
    "    # Make the changes to the database persistent\n",
    "    db.commit()\n",
    "    # Update columns with values\n",
    "    cur.execute(\"UPDATE \"+schema+\".\"+streetblocktable+\" AS a \\\n",
    "    SET morpho_id=b.gid \\\n",
    "    FROM \"+schema+\".\"+morphotable+\" AS b \\\n",
    "    WHERE ST_Within(ST_PointOnSurface(a.the_geom),b.geom)\")\n",
    "    # Make the changes to the database persistent\n",
    "    db.commit()   \n",
    "    # Update columns with values\n",
    "    cur.execute(\"UPDATE \"+schema+\".\"+streetblocktable+\" AS a \\\n",
    "    SET morpho_type=b.type \\\n",
    "    FROM \"+schema+\".\"+morphotable+\" AS b \\\n",
    "    WHERE ST_Within(ST_PointOnSurface(a.the_geom),b.geom)\")\n",
    "    # Make the changes to the database persistent\n",
    "    db.commit()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_artifact(db, schema, table):\n",
    "    ## Enter postgresqgl table's mane\n",
    "    temp_join = \"temp_join\"\n",
    "\n",
    "    # Open a cursor to perform database operations\n",
    "    cur=db.cursor()\n",
    "\n",
    "    #### Identify the artifact polygon (identified by selection on area and perimeter) \n",
    "    #### and all polygons non-artifact polygons touching them.\n",
    "\n",
    "    # Drop table if exists:\n",
    "    cur.execute(\"DROP TABLE IF EXISTS \"+user[\"schema\"]+\".\"+temp_join)\n",
    "    # Make the changes to the database persistent\n",
    "    db.commit()\n",
    "\n",
    "    # Subquery\n",
    "    subquery1=\"WITH \\\n",
    "    artifacts AS (\\\n",
    "    SELECT * FROM \"+schema+\".\"+table+\" AS p \\\n",
    "    WHERE (p.compactness>6.5 AND p.area<10000) OR (p.area<2200) OR (p.compactness>15)), \\\n",
    "    \\\n",
    "    basepolygons AS (\\\n",
    "    SELECT * FROM \"+schema+\".\"+table+\" AS p \\\n",
    "    WHERE NOT EXISTS (SELECT a.gid FROM artifacts AS a WHERE p.gid=a.gid)) \\\n",
    "    \\\n",
    "    SELECT a.the_geom, a.gid AS artifact_gid, b.gid AS base_gid, a.morpho_id, a.morpho_type, \\\n",
    "    ST_Length(ST_CollectionExtract(ST_Intersection(a.the_geom, b.the_geom), 2)) AS length \\\n",
    "    FROM artifacts a INNER JOIN basepolygons b ON (ST_Touches(a.the_geom,b.the_geom) AND a.morpho_id=b.morpho_id) \\\n",
    "    WHERE ST_Length(ST_CollectionExtract(ST_Intersection(a.the_geom, b.the_geom), 2)) > 0 \\\n",
    "    ORDER BY a.gid\"\n",
    "    \n",
    "    # Query\n",
    "    query=\"CREATE TABLE \"+schema+\".\"+temp_join+\" AS (\"\n",
    "    query+=subquery1+\")\"\n",
    "\n",
    "    # Execute the CREATE TABLE query \n",
    "    cur.execute(query)\n",
    "    # Make the changes to the database persistent\n",
    "    db.commit()\n",
    "\n",
    "    #### For each artifact, keep only the record regarding to the longer shared lenght with basepolygon.\n",
    "\n",
    "    # Set the name of the temporary layer\n",
    "    global temp_maxborder\n",
    "    temp_maxborder=\"temp_maxborder\"\n",
    "\n",
    "    # Drop table if exists:\n",
    "    cur.execute(\"DROP TABLE IF EXISTS \"+schema+\".\"+temp_maxborder)\n",
    "    # Make the changes to the database persistent\n",
    "    db.commit()\n",
    "\n",
    "    # Subquery for extraction of linestrings from different sources\n",
    "    subquery=\"WITH \\\n",
    "    max_value AS(\\\n",
    "    SELECT artifact_gid, max(length) AS shared_length \\\n",
    "    FROM \"+schema+\".\"+temp_join+\" \\\n",
    "    GROUP BY artifact_gid ORDER BY artifact_gid) \\\n",
    "    \\\n",
    "    SELECT a.* \\\n",
    "    FROM \"+schema+\".\"+temp_join+\" AS a \\\n",
    "    INNER JOIN max_value AS b \\\n",
    "    ON (a.length = b.shared_length AND a.artifact_gid = b.artifact_gid)\"\n",
    "\n",
    "    ## Query\n",
    "    query=\"CREATE TABLE \"+schema+\".\"+temp_maxborder+\" AS (\"\n",
    "    query+=subquery+\")\"\n",
    "    # Execute the CREATE TABLE query \n",
    "    cur.execute(query)\n",
    "    # Make the changes to the database persistent\n",
    "    db.commit()\n",
    "\n",
    "    return find_nbrrowm(db, schema, temp_maxborder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_artifacts(db, schema, table):\n",
    "    # Set the name of the temporary layer\n",
    "    union_table=\"union_table\"\n",
    "\n",
    "    # Drop table if exists:\n",
    "    cur.execute(\"DROP TABLE IF EXISTS \"+schema+\".\"+union_table)\n",
    "    # Make the changes to the database persistent\n",
    "    db.commit()\n",
    "\n",
    "    # Subquery for extraction of linestrings from different sources\n",
    "    subquery=\"SELECT a.*, b.base_gid AS union_gid FROM \"+schema+\".\"+table+\" AS a \\\n",
    "    LEFT JOIN \"+schema+\".\"+temp_maxborder+\" AS b ON a.gid=b.artifact_gid\"\n",
    "\n",
    "    ## Query\n",
    "    query=\"CREATE TABLE \"+schema+\".\"+union_table+\" AS (\"\n",
    "    query+=subquery+\")\"\n",
    "    # Execute the CREATE TABLE query \n",
    "    cur.execute(query)\n",
    "    # Make the changes to the database persistent\n",
    "    db.commit()\n",
    "    \n",
    "    # Add a SERIAL PRIMARY KEY on the table \n",
    "    cur.execute(\"UPDATE \"+schema+\".\"+union_table+\" SET union_gid=gid WHERE union_gid IS NULL\")\n",
    "    # Make the changes to the database persistent\n",
    "    db.commit()\n",
    "    \n",
    "    # Drop table if exists:\n",
    "    cur.execute(\"DROP TABLE IF EXISTS \"+schema+\".\"+table)\n",
    "    # Make the changes to the database persistent\n",
    "    db.commit()\n",
    "\n",
    "    # Subquery for extraction of linestrings from different sources\n",
    "    subquery=\"SELECT ST_Union(the_geom) AS the_geom, union_gid AS gid \\\n",
    "    FROM \"+schema+\".\"+union_table+\" \\\n",
    "    GROUP BY union_gid ORDER BY union_gid\"\n",
    "\n",
    "    ## Query\n",
    "    query=\"CREATE TABLE \"+schema+\".\"+table+\" AS (\"\n",
    "    query+=subquery+\")\"\n",
    "    # Execute the CREATE TABLE query \n",
    "    cur.execute(query)\n",
    "    # Make the changes to the database persistent\n",
    "    db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Remove artifacts in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect to an existing database\n",
    "db=pg.connect(dbname=user[\"dbname\"], user=user[\"user\"], password=user[\"password\"], host=user[\"host\"])\n",
    "# Open a cursor to perform database operations\n",
    "cur=db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Copy the current street blocks in a temporary table for processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Enter postgresqgl table's name\n",
    "user[\"street_blocks_temp\"] = \"street_blocks_temp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop table if exists:\n",
    "cur.execute(\"DROP TABLE IF EXISTS \"+user[\"schema\"]+\".\"+user[\"street_blocks_temp\"])\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "\n",
    "# Subquery for extraction of linestrings from different sources\n",
    "subquery=\"SELECT * FROM \"+user[\"schema\"]+\".\"+user[\"street_blocks_with_artifacts\"]\n",
    "\n",
    "## Query\n",
    "query=\"CREATE TABLE \"+user[\"schema\"]+\".\"+user[\"street_blocks_temp\"]+\" AS (\"\n",
    "query+=subquery+\")\"\n",
    "# Execute the CREATE TABLE query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute morphological metrics\n",
    "add_area_perimeter_compactness(db,user[\"schema\"],user[\"street_blocks_temp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute appartenance to morphological zones\n",
    "add_morphoid_morphotype(db,user[\"schema\"],user[\"street_blocks_temp\"], user[\"morphotable\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove artifacts in a loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Saving current time for processing time management\n",
    "begintime_cleaning=time.time()\n",
    " \n",
    "# Compute the initial number of artifact\n",
    "nbr_artifact=find_artifact(db,user[\"schema\"],user[\"street_blocks_temp\"])\n",
    "\n",
    "# Remove artifacts in a loop\n",
    "if nbr_artifact==0:\n",
    "    print \"There is no artifact to be removed\"\n",
    "else:\n",
    "    nbr_loop=0\n",
    "    while nbr_artifact > 0:\n",
    "        nbr_loop+=1\n",
    "        print \"Pass n°\"+str(nbr_loop)+\".\\n\"\n",
    "        print str(nbr_artifact)+\" artifacts have to be removed.\\n\"\n",
    "        remove_artifacts(db,user[\"schema\"],user[\"street_blocks_temp\"])\n",
    "        print \"Artifacts successfully removed.\\n\\n\"\n",
    "        add_area_perimeter_compactness(db,user[\"schema\"], user[\"street_blocks_temp\"])\n",
    "        add_morphoid_morphotype(db,user[\"schema\"],user[\"street_blocks_temp\"], user[\"morphotable\"])\n",
    "        nbr_artifact=find_artifact(db,user[\"schema\"], user[\"street_blocks_temp\"])\n",
    "    print \"All artifacts were removed after \"+str(nbr_loop)+\" passes.\"\n",
    "    \n",
    "## Print\n",
    "print print_processing_time(begintime_cleaning, \"Artifacts where removed in \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Close cursor and communication with the database\n",
    "cur.close()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Copy the result in the a new PostGis table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Enter postgresqgl table's name\n",
    "user[\"street_blocks\"] = \"street_blocks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect to an existing database\n",
    "db=pg.connect(dbname=user[\"dbname\"], user=user[\"user\"], password=user[\"password\"], host=user[\"host\"])\n",
    "# Open a cursor to perform database operations\n",
    "cur=db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop table if exists:\n",
    "cur.execute(\"DROP TABLE IF EXISTS \"+user[\"schema\"]+\".\"+user[\"street_blocks\"])\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "\n",
    "# Subquery for extraction of linestrings from different sources\n",
    "subquery=\"SELECT * FROM \"+user[\"schema\"]+\".\"+user[\"street_blocks_temp\"]\n",
    "\n",
    "## Query\n",
    "query=\"CREATE TABLE \"+user[\"schema\"]+\".\"+user[\"street_blocks\"]+\" AS (\"\n",
    "query+=subquery+\")\"\n",
    "# Execute the CREATE TABLE query \n",
    "cur.execute(query)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Close cursor and communication with the database\n",
    "cur.close()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Compute some statistics about the street blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect to an existing database\n",
    "db=pg.connect(dbname=user[\"dbname\"], user=user[\"user\"], password=user[\"password\"], host=user[\"host\"])\n",
    "# Open a cursor to perform database operations\n",
    "cur=db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Max number of records to return from the query\n",
    "limitnumber=20\n",
    "# Query\n",
    "query=\"SELECT * FROM \"+user[\"schema\"]+\".\"+user[\"street_blocks\"]+\" LIMIT \"+str(limitnumber)\n",
    "# Execute query through panda\n",
    "df=pd.read_sql(query, db)\n",
    "# Show dataframe\n",
    "df.head(limitnumber)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Clean Postgis database for tables not needed anymore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create list of tables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a list of tables name to be deleted\n",
    "tablestoremove=[]\n",
    "# Append the list with temporary layers not needed anymore\n",
    "tablestoremove.append(\"tile\")\n",
    "tablestoremove.append(\"aoi_tile\")\n",
    "[tablestoremove.append(linestrings[i]) for i in linestrings.keys()]\n",
    "[tablestoremove.append(osm_line[i]) for i in osm_line.keys()]\n",
    "[tablestoremove.append(osm_polygon[i]) for i in osm_polygon.keys()]\n",
    "tablestoremove.append(\"street_blocks_temp\")\n",
    "tablestoremove.append(\"temp_join\")\n",
    "tablestoremove.append(\"temp_maxborder\")\n",
    "tablestoremove.append(\"union_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create set of SQL queries\n",
    "queries=[]\n",
    "[queries.append(\"DROP TABLE IF EXISTS %s.%s\"%(user[\"schema\"],table)) for table in tablestoremove]\n",
    "print \";\\n\".join(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Execute the queries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect to an existing database\n",
    "db=pg.connect(dbname=user[\"dbname\"], user=user[\"user\"], password=user[\"password\"], host=user[\"host\"])\n",
    "# Open a cursor to perform database operations\n",
    "cur=db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Execute the queries \n",
    "cur.execute(\";\".join(queries))\n",
    "# Make the changes to the database persistent\n",
    "db.commit()\n",
    "# Make vaccum\n",
    "vacuum(db)\n",
    "# Close cursor and communication with the database\n",
    "cur.close()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop database schema dedicated to topological operations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Execute the query \n",
    "cur.execute(\"DROP SCHEMA IF EXISTS %s CASCADE\"%topo_layer)\n",
    "# Make the changes to the database persistent\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make vaccum\n",
    "vacuum(db)\n",
    "# Close cursor and communication with the database\n",
    "cur.close()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> *-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*- </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export urban blocks in Shapefile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dsjdsodlksdds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Shapefile of the morphological delineation\n",
    "pathtofile1=\"F:\\\\MAUPP\\\\Landuse_mapping\\\\City_block_extraction\\\\Test_extraction_bloc\\\\Data\\\\Zone_morpho_Ouaga_ajusted_ortho.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Build the osm2pgsql command-line\n",
    "cmdline=\"set PGPASSWORD=\"+user[\"password\"]+\"\\n\"\n",
    "cmdline+=\"pgsql2shp -s -d -I\"+\" \"\n",
    "cmdline+=pathtofile1+\" \"+user[\"schema\"]+\".\"+user[\"blocks\"]+\" \"\n",
    "cmdline+=\"|\"+\" \"\n",
    "cmdline+=\"psql -d \"+user[\"dbname\"]+\" -h \"+user[\"host\"]+\" -U \"+user[\"user\"]\n",
    "## Create temp bash file for osm2pgsql\n",
    "outputcsv=tempfile.gettempdir()+\"\\\\tmp_bash.bat\" # Define the csv output file name\n",
    "f = open(outputcsv, 'w')\n",
    "f.write(cmdline)\n",
    "f.close()\n",
    "\n",
    "print cmdline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cmd\n",
    "%Temp%\\tmp_bash.bat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Print processing time for the full process\n",
    "print_processing_time(begintime_blockextraction_full, \"Urban blocks extracted in: \")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
